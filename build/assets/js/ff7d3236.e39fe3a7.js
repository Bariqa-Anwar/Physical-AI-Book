"use strict";(self.webpackChunkdocusourus_book=self.webpackChunkdocusourus_book||[]).push([[314],{3921:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>a,default:()=>l,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"module4/gpt-hri","title":"LLM for Command Understanding and Response","description":"Once speech has been converted to text using a Speech-to-Text (STT) model like Whisper, the next step in achieving natural Human-Robot Interaction (HRI) is to interpret these text commands and generate an appropriate response or action. Large Language Models (LLMs) like OpenAI\'s GPT series are exceptionally good at understanding natural language, extracting intent, and generating coherent text, making them ideal for this role.","source":"@site/docs/module4/gpt-hri.md","sourceDirName":"module4","slug":"/module4/gpt-hri","permalink":"/docs/module4/gpt-hri","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module4/gpt-hri.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Speech-to-Text with OpenAI Whisper","permalink":"/docs/module4/whisper-stt"}}');var s=t(4848),r=t(8453);const i={sidebar_position:2},a="LLM for Command Understanding and Response",p={},d=[{value:"1. Setting up the Python Environment for OpenAI API (GPT)",id:"1-setting-up-the-python-environment-for-openai-api-gpt",level:2},{value:"2. Creating a <code>command_parser_node.py</code>",id:"2-creating-a-command_parser_nodepy",level:2},{value:"3. Creating a <code>text_to_speech_node.py</code>",id:"3-creating-a-text_to_speech_nodepy",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"llm-for-command-understanding-and-response",children:"LLM for Command Understanding and Response"})}),"\n",(0,s.jsx)(n.p,{children:"Once speech has been converted to text using a Speech-to-Text (STT) model like Whisper, the next step in achieving natural Human-Robot Interaction (HRI) is to interpret these text commands and generate an appropriate response or action. Large Language Models (LLMs) like OpenAI's GPT series are exceptionally good at understanding natural language, extracting intent, and generating coherent text, making them ideal for this role."}),"\n",(0,s.jsx)(n.p,{children:"This section will demonstrate how to integrate an LLM (specifically GPT) into a ROS 2 node to parse human commands, generate a natural language response, and integrate with the robot's action system."}),"\n",(0,s.jsx)(n.h2,{id:"1-setting-up-the-python-environment-for-openai-api-gpt",children:"1. Setting up the Python Environment for OpenAI API (GPT)"}),"\n",(0,s.jsxs)(n.p,{children:["As with Whisper, you will use the OpenAI API. Ensure your ",(0,s.jsx)(n.code,{children:"OPENAI_API_KEY"})," environment variable is set and the ",(0,s.jsx)(n.code,{children:"openai"})," Python library is installed in your ROS 2 virtual environment."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Activate your ROS 2 Python virtual environment first\n# source ~/ros2_ws/venv/bin/activate\npip install openai\n"})}),"\n",(0,s.jsxs)(n.h2,{id:"2-creating-a-command_parser_nodepy",children:["2. Creating a ",(0,s.jsx)(n.code,{children:"command_parser_node.py"})]}),"\n",(0,s.jsxs)(n.p,{children:["This ROS 2 node will subscribe to the transcribed text from the ",(0,s.jsx)(n.code,{children:"speech_to_text_node.py"}),", send it to the GPT API, interpret the command, and formulate a response."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# ros2_ws/src/my_robot_pkg/nodes/command_parser_node.py\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nimport openai\nimport os\n\nclass CommandParserNode(Node):\n    def __init__(self):\n        super().__init__(\'command_parser_node\')\n        self.subscription = self.create_subscription(\n            String,\n            \'/human_speech_text\', # Subscribe to transcribed speech\n            self.listener_callback,\n            10)\n        self.subscription  # prevent unused variable warning\n        self.robot_response_publisher = self.create_publisher(String, \'/robot_response_text\', 10)\n        self.openai_client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))\n\n        self.get_logger().info("Command Parser Node initialized. Waiting for commands...")\n\n    def listener_callback(self, msg: String):\n        human_command = msg.data\n        self.get_logger().info(f\'Received command: "{human_command}"\')\n\n        # Use GPT to understand command and generate response\n        try:\n            response = self.openai_client.chat.completions.create(\n                model="gpt-3.5-turbo", # Or "gpt-4"\n                messages=[\n                    {"role": "system", "content": "You are a helpful robot assistant. Respond concisely."},\n                    {"role": "user", "content": human_command}\n                ]\n            )\n            robot_response = response.choices[0].message.content\n            self.get_logger().info(f\'GPT responded: "{robot_response}"\')\n\n            # Publish the robot\'s natural language response\n            response_msg = String()\n            response_msg.data = robot_response\n            self.robot_response_publisher.publish(response_msg)\n\n        except Exception as e:\n            self.get_logger().error(f"Error calling OpenAI GPT API: {e}")\n            response_msg = String()\n            response_msg.data = "I\'m sorry, I could not process that command."\n            self.robot_response_publisher.publish(response_msg)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CommandParserNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsxs)(n.h2,{id:"3-creating-a-text_to_speech_nodepy",children:["3. Creating a ",(0,s.jsx)(n.code,{children:"text_to_speech_node.py"})]}),"\n",(0,s.jsx)(n.p,{children:"To complete the auditory interaction loop, the robot's text response needs to be converted back into speech. A simple Text-to-Speech (TTS) node can achieve this."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# ros2_ws/src/my_robot_pkg/nodes/text_to_speech_node.py\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\n# import gtts # Google Text-to-Speech\n# from playsound import playsound # For playing audio - requires platform-specific setup\n# import os\n\nclass TextToSpeechNode(Node):\n    def __init__(self):\n        super().__init__('text_to_speech_node')\n        self.subscription = self.create_subscription(\n            String,\n            '/robot_response_text', # Subscribe to robot's text responses\n            self.listener_callback,\n            10)\n        self.subscription # prevent unused variable warning\n        self.get_logger().info(\"Text-to-Speech Node initialized. Waiting for robot responses...\")\n\n    def listener_callback(self, msg: String):\n        robot_text = msg.data\n        self.get_logger().info(f'Received robot response: \"{robot_text}\"')\n\n        try:\n            # Convert text to speech (conceptual)\n            # For a real implementation, you would use a TTS library like gTTS\n            # tts = gtts.gTTS(robot_text, lang='en')\n            # audio_file = \"robot_response.mp3\"\n            # tts.save(audio_file)\n            # playsound(audio_file)\n            # os.remove(audio_file) # Clean up audio file\n\n            self.get_logger().info(f'Simulating speech for: \"{robot_text}\"')\n        except Exception as e:\n            self.get_logger().error(f\"Error during text-to-speech conversion: {e}\")\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = TextToSpeechNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})})]})}function l(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var o=t(6540);const s={},r=o.createContext(s);function i(e){const n=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);